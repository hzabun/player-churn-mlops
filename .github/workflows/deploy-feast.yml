name: Deploy Feature Store

on:
  # Trigger on push to main (includes PR merges) when feature store changes
  push:
    branches: [main]
    paths:
      - "feature_store/**"
      - "data/processed/player_features.parquet"
  # Allow manual deployment trigger from GitHub UI
  workflow_dispatch:

jobs:
  deploy-feast:
    name: Deploy Feast Feature Store
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install Feast
        run: |
          python -m pip install --upgrade pip
          pip install feast pandas pyarrow

      - name: Run feast apply
        run: |
          cd feature_store
          feast apply

      - name: Verify deployment
        run: |
          cd feature_store
          feast feature-views list
          feast entities list

      # Archive registry to GitHub Actions artifacts (temporary backup, 30 days)
      # Accessible via: Actions → Workflow run → Artifacts section
      # This is NOT persistent storage - use S3/GCS for production
      - name: Archive Feast registry (GitHub Artifacts)
        uses: actions/upload-artifact@v4
        with:
          name: feast-registry-${{ github.sha }}
          path: feature_store/data/registry.db
          retention-days: 30

      # TODO: Enable this when S3 bucket is ready
      # This provides persistent storage for the registry
      # - name: Sync registry to S3 (Production Storage)
      #   run: |
      #     aws s3 cp feature_store/data/registry.db s3://your-bucket/feast/registry.db
      #     aws s3 cp feature_store/data/registry.db s3://your-bucket/feast/registry-$(date +%Y%m%d-%H%M%S).db  # Backup with timestamp
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
